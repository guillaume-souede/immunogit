{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581ade3b-f749-469b-b29c-8e4cb8e6a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import json\n",
    "from bioservices import BioModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c596b0a2-e96c-47d3-89e8-cdc11493980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    [bioservices.BioModels:363]: \u001b[0m \u001b[32mInitialising BioModels service (REST)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "s = BioModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e9c9c8-bd13-4ecf-977b-ea62a45a10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_models(query, page_size=10):\n",
    "    \"\"\"\n",
    "    Fonction pour récupérer tous les modèles correspondant à la requête avec pagination.\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            search_results = s.search(query, offset=offset)\n",
    "            \n",
    "            if 'models' not in search_results or not search_results['models']:\n",
    "                break\n",
    "            \n",
    "            models.extend(search_results['models'])\n",
    "            offset += page_size\n",
    "            print(f\"Page {offset // page_size} téléchargée, {len(search_results['models'])} modèles récupérés.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la récupération des modèles : {e}\")\n",
    "            break\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9503e0b0-cf7d-4900-9eb0-396c4b216e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model_file(model_id, directory):\n",
    "    \"\"\"\n",
    "    Télécharge le fichier sbml du modele\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Créer le chemin du ZIP\n",
    "        zip_filename = f\"{model_id}.zip\"\n",
    "        zip_path = os.path.join(directory, zip_filename)\n",
    "\n",
    "        # Télécharger le ZIP\n",
    "        s.get_model_download(model_id, output_filename=zip_path)\n",
    "\n",
    "        # Extraire uniquement le premier fichier .xml trouvé\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            xml_files = [\n",
    "                f for f in zip_ref.namelist()\n",
    "                if ((f.lower().endswith('.xml') or f.lower().endswith('.XML'))\n",
    "                    and not f.lower().endswith('_urn.xml') \n",
    "                    and not f.lower().endswith('manifest.xml'))\n",
    "                ]\n",
    "\n",
    "            if not xml_files:\n",
    "                xml_files = [f for f in zip_ref.namelist()\n",
    "                             if f.lower().endswith('.sbml') \n",
    "                             and not f.lower().endswith('_urn.xml') \n",
    "                             and not f.lower().endswith('manifest.xml')]\n",
    "    \n",
    "            if not xml_files:\n",
    "                print(f\"Aucun fichier SBML/XML trouvÃ© dans le ZIP pour {model_id}\")\n",
    "                return None\n",
    "\n",
    "            xml_filename = xml_files[0] \n",
    "            zip_ref.extract(xml_filename, directory)\n",
    "\n",
    "            extracted_path = os.path.join(directory, os.path.basename(xml_filename))\n",
    "            print(f\"Fichier SBML extrait : {extracted_path}\")\n",
    "\n",
    "        # Supprimer le fichier ZIP\n",
    "        os.remove(zip_path)\n",
    "\n",
    "        return extracted_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du téléchargement du modéle {model_id}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4850e9ab-fb98-4847-9093-75e0e7e00e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model_with_metadata(model_data, base_directory) :\n",
    "    \"\"\"\n",
    "    Download a model and its metadata, then save them into a ZIP file.\n",
    "\n",
    "    Args :\n",
    "        model_data (dict) : A dictionary containing model information, including at least 'id' and 'url'.\n",
    "        base_directory (str) : Path to the root directory where the model should be saved.\n",
    "\n",
    "    Returns :\n",
    "        None\n",
    "    \"\"\"\n",
    "    try :\n",
    "        model_id = model_data['id']\n",
    "        #sbml_url = model_data.get('url', None)\n",
    "        title = model_data.get('name', \"\").lower()\n",
    "        keywords = model_data.get('submitter_keywords', \"\").lower()\n",
    "        immun = model_data.get('immun', \"\").lower()\n",
    "        \n",
    "        def contains_keyword(data, keyword) :\n",
    "            \"\"\"\n",
    "            Recursively search for a keyword ('kw') in all string values of a nested element.\n",
    "\n",
    "            Args :\n",
    "                data (any) : The data to search (can be dict, list, str).\n",
    "                keyword (str) : The keyword to search for.\n",
    "\n",
    "            Returns :\n",
    "                bool : True if keyword is found. False otherwise.\n",
    "            \"\"\"\n",
    "            if isinstance(data, dict) :\n",
    "                return any(contains_keyword(v, keyword) for v in data.values())\n",
    "            elif isinstance(data, list) :\n",
    "                return any(contains_keyword(item, keyword) for item in data)\n",
    "            elif isinstance(data, str) :\n",
    "                return keyword.lower() in data.lower()\n",
    "            return False\n",
    "\n",
    "\n",
    "        # Retrieve full metadata\n",
    "        try :\n",
    "            full_metadata = s.get_model(model_id)\n",
    "        except Exception as e :\n",
    "            print(f\"Error retrieving full metadata for {model_id} : {e}\")\n",
    "            return\n",
    "\n",
    "        # Determine destination directory based on content\n",
    "        if contains_keyword(full_metadata, \"immun\") :\n",
    "            directory = os.path.join(base_directory, \"immun\")\n",
    "            directory = os.path.join(directory, \"Curated_models\" if \"BIOM\" in model_id else \"No_Curated_models\")\n",
    "        elif contains_keyword(full_metadata, \"T cell\") :\n",
    "            directory = os.path.join(base_directory, \"T-cell\")\n",
    "            directory = os.path.join(directory, \"Curated_models\" if \"BIOM\" in model_id else \"No_Curated_models\")\n",
    "        else :\n",
    "            return\n",
    "\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        # Download SBML file\n",
    "        model_path = download_model_file(model_id, directory)\n",
    "        if model_path is None :\n",
    "            return\n",
    "\n",
    "        # Save metadata as JSON\n",
    "        metadata_filename = f\"{model_id}_metadata.json\"\n",
    "        metadata_path = os.path.join(directory, metadata_filename)\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f :\n",
    "            json.dump(full_metadata, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # Create ZIP file containing model and metadata\n",
    "        zip_filename = os.path.join(directory, f\"{model_id}.zip\")\n",
    "        with zipfile.ZipFile(zip_filename, 'w') as zipf :\n",
    "            zipf.write(model_path, os.path.basename(model_path))\n",
    "            zipf.write(metadata_path, os.path.basename(metadata_path))\n",
    "\n",
    "        # Remove temporary files\n",
    "        os.remove(model_path)\n",
    "        os.remove(metadata_path)\n",
    "\n",
    "        print(f\"Model {model_id} and its metadata saved to {zip_filename}\")\n",
    "\n",
    "    except Exception as e :\n",
    "        print(f\"An error occurred while processing model {model_data['id']} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19fd1571-3782-44c0-b41e-be0416862fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Requête mise à jour\n",
    "    query = (\n",
    "        'boolean AND modelformat:\"SBML\" AND NOT modellingapproach:\"logical model\"'\n",
    "    )\n",
    "\n",
    "    # Répertoire principal\n",
    "    base_directory = \"downloaded_models_boolean\"\n",
    "    os.makedirs(base_directory, exist_ok=True)\n",
    "\n",
    "    # Obtenir tous les modèles\n",
    "    models = get_all_models(query)\n",
    "\n",
    "    # Télécharger chaque modèle et les classer\n",
    "    for model_data in models:\n",
    "        download_model_with_metadata(model_data, base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb115c43-fcc1-4037-af0b-fa0bf9efa4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 téléchargée, 10 modèles récupérés.\n",
      "Page 2 téléchargée, 5 modèles récupérés.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    [bioservices.BioModels:171]: \u001b[0m \u001b[32mSaving file MODEL2312140001.zip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier SBML extrait : downloaded_models_logical\\T-cell\\No_Curated_models\\MiDAS_Cell_Cycle_Arrests_Apoptosis_Fine.XML\n",
      "Model MODEL2312140001 and its metadata saved to downloaded_models_logical\\T-cell\\No_Curated_models\\MODEL2312140001.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    [bioservices.BioModels:171]: \u001b[0m \u001b[32mSaving file MODEL2006170002.zip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier SBML extrait : downloaded_models_logical\\T-cell\\No_Curated_models\\Sizek_Regan_PI3K_growth_CellCycle_Apoptosis.sbml\n",
      "Model MODEL2006170002 and its metadata saved to downloaded_models_logical\\T-cell\\No_Curated_models\\MODEL2006170002.zip\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cda181-ef6f-4640-ac4b-0cb3db609dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
