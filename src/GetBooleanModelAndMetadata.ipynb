{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3789fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import json\n",
    "from bioservices import BioModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201bea5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "s = BioModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a53ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_all_models(query, page_size=10):\n",
    "    \"\"\"\n",
    "    Retrieve all models matching a query with pagination.\n",
    "\n",
    "    Args:\n",
    "        query (str) : The search query to use.\n",
    "        page_size (int, optional) : Number of models to retrieve per page. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        list : A list of all models retrieved.\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            search_results = s.search(query, offset=offset)\n",
    "\n",
    "            if 'models' not in search_results or not search_results['models']:\n",
    "                print(\"No more models found. Retrieval complete.\")\n",
    "                break\n",
    "\n",
    "            models.extend(search_results['models'])\n",
    "            print(f\"Downloaded page {offset // page_size + 1}: retrieved {len(search_results['models'])} models.\")\n",
    "            offset += page_size\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while retrieving models ! See : {e}\")\n",
    "            break\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537cf667",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def download_model_file(model_id, sbml_url, directory):\n",
    "    \"\"\"\n",
    "    Download the SBML file for a given model.\n",
    "\n",
    "    Args:\n",
    "        model_id (str) : model identifier.\n",
    "        sbml_url (str) : URL pointing to the SBML file.\n",
    "        directory (str) : local directory used to save file.\n",
    "\n",
    "    Returns:\n",
    "        str or None : full path to the downloaded file, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    try :\n",
    "        sbml_filename = f\"{model_id}.xml\"\n",
    "        model_path = os.path.join(directory, sbml_filename)\n",
    "\n",
    "        response = requests.get(sbml_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(model_path, 'wb') as f :\n",
    "                f.write(response.content)\n",
    "            print(f\"Model {model_id} successfully downloaded.\")\n",
    "        else :\n",
    "            raise RuntimeError(f\"Failed to download model {model_id} ; See error HTTP {response.status_code}\")\n",
    "\n",
    "        return model_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading model {model_id} ; See : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a547c000",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def download_model_with_metadata(model_data, base_directory) :\n",
    "    \"\"\"\n",
    "    Download a model and its metadata, then save them into a ZIP file.\n",
    "\n",
    "    Args :\n",
    "        model_data (dict) : A dictionary containing model information, including at least 'id' and 'url'.\n",
    "        base_directory (str) : Path to the root directory where the model should be saved.\n",
    "\n",
    "    Returns :\n",
    "        None\n",
    "    \"\"\"\n",
    "    try :\n",
    "        model_id = model_data['id']\n",
    "        sbml_url = model_data.get('url', None)\n",
    "        title = model_data.get('name', \"\").lower()\n",
    "        keywords = model_data.get('submitter_keywords', \"\").lower()\n",
    "        immun = model_data.get('immun', \"\").lower()\n",
    "        \n",
    "        def contains_keyword(data, keyword) :\n",
    "            \"\"\"\n",
    "            Recursively search for a keyword ('kw') in all string values of a nested element.\n",
    "\n",
    "            Args :\n",
    "                data (any) : The data to search (can be dict, list, str).\n",
    "                keyword (str) : The keyword to search for.\n",
    "\n",
    "            Returns :\n",
    "                bool : True if keyword is found. False otherwise.\n",
    "            \"\"\"\n",
    "            if isinstance(data, dict) :\n",
    "                return any(contains_keyword(v, keyword) for v in data.values())\n",
    "            elif isinstance(data, list) :\n",
    "                return any(contains_keyword(item, keyword) for item in data)\n",
    "            elif isinstance(data, str) :\n",
    "                return keyword.lower() in data.lower()\n",
    "            return False\n",
    "\n",
    "        if not sbml_url :\n",
    "            print(f\"No URL found for model {model_id}.\")\n",
    "            return\n",
    "\n",
    "        # Retrieve full metadata\n",
    "        try :\n",
    "            full_metadata = s.get_model(model_id)\n",
    "        except Exception as e :\n",
    "            print(f\"Error retrieving full metadata for {model_id} : {e}\")\n",
    "            return\n",
    "\n",
    "        # Determine destination directory based on content\n",
    "        if contains_keyword(full_metadata, \"immun\") :\n",
    "            directory = os.path.join(base_directory, \"immun\")\n",
    "            directory = os.path.join(directory, \"Curated_models\" if \"BIOM\" in model_id else \"No_Curated_models\")\n",
    "        elif contains_keyword(full_metadata, \"T cell\") :\n",
    "            directory = os.path.join(base_directory, \"T-cell\")\n",
    "            directory = os.path.join(directory, \"Curated_models\" if \"BIOM\" in model_id else \"No_Curated_models\")\n",
    "        else :\n",
    "            return\n",
    "\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        # Download SBML file\n",
    "        model_path = download_model_file(model_id, sbml_url, directory)\n",
    "        if model_path is None :\n",
    "            return\n",
    "\n",
    "        # Save metadata as JSON\n",
    "        metadata_filename = f\"{model_id}_metadata.json\"\n",
    "        metadata_path = os.path.join(directory, metadata_filename)\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f :\n",
    "            json.dump(full_metadata, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # Create ZIP file containing model and metadata\n",
    "        zip_filename = os.path.join(directory, f\"{model_id}.zip\")\n",
    "        with zipfile.ZipFile(zip_filename, 'w') as zipf :\n",
    "            zipf.write(model_path, os.path.basename(model_path))\n",
    "            zipf.write(metadata_path, os.path.basename(metadata_path))\n",
    "\n",
    "        # Remove temporary files\n",
    "        os.remove(model_path)\n",
    "        os.remove(metadata_path)\n",
    "\n",
    "        print(f\"Model {model_id} and its metadata saved to {zip_filename}\")\n",
    "\n",
    "    except Exception as e :\n",
    "        print(f\"An error occurred while processing model {model_data['id']} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d946b3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main() :\n",
    "    \"\"\"\n",
    "    Main function to run whole file.\n",
    "    \"\"\"\n",
    "    query = (\n",
    "        'boolean AND modelformat:\"SBML\" AND NOT modellingapproach:\"logical model\"'\n",
    "    )\n",
    "\n",
    "    base_directory = \"downloaded_models_boolean\"\n",
    "    os.makedirs(base_directory, exist_ok=True)\n",
    "\n",
    "    models = get_all_models(query)\n",
    "\n",
    "    for model_data in models :\n",
    "        download_model_with_metadata(model_data, base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
