{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODULES\n",
    "\"\"\"\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import zipfile as z\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\"\"\"\n",
    "PATHS\n",
    "\"\"\"\n",
    "current_path = os.getcwd()\n",
    "# BELOW PATH IS IMPORTANT AND TO RE-USE !\n",
    "root_path = os.path.abspath(os.path.join(current_path, \"..\"))\n",
    "\n",
    "os.makedirs(os.path.join(root_path, \"models/BioModels/SBML\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(root_path, \"models/Reactome/SBML\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(root_path, \"models/Reactome/SBGN\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(root_path, \"metadata\"), exist_ok=True)\n",
    "print(\"Structure : Done.\")\n",
    "\n",
    "\"\"\"\n",
    "COMMON VARIABLES\n",
    "\"\"\"\n",
    "BLUE = '\\033[94m'\n",
    "RED = '\\033[91m'\n",
    "RESET = '\\033[0m'"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def json_metadata_extractor(json_data, source=None):\n",
    "    \"\"\"Extract some ir(relevant) metadata from a given JSON file.\"\"\"\n",
    "    return {\n",
    "        \"name\": json_data.get(\"name\"),\n",
    "        \"description\": json_data.get(\"description\"),\n",
    "        \"format\": json_data.get(\"format\", {}).get(\"name\"),\n",
    "        \"publication\": {\n",
    "            \"title\": json_data.get(\"publication\", {}).get(\"title\"),\n",
    "            \"journal\": json_data.get(\"publication\", {}).get(\"journal\"),\n",
    "            \"year\": json_data.get(\"publication\", {}).get(\"year\"),\n",
    "            \"authors\": [\n",
    "                {\n",
    "                    \"name\": author.get(\"name\"),\n",
    "                    \"institution\": author.get(\"institution\"),\n",
    "                    \"orcid\": author.get(\"orcid\")\n",
    "                }\n",
    "                for author in json_data.get(\"publication\", {}).get(\"authors\", [])\n",
    "            ],\n",
    "            \"link\": json_data.get(\"publication\", {}).get(\"link\")\n",
    "        },\n",
    "        \"files\": [\n",
    "            {\n",
    "                \"name\": file_data.get(\"name\"),\n",
    "                \"description\": file_data.get(\"description\"),\n",
    "                \"fileSize\": file_data.get(\"fileSize\"),\n",
    "                \"mimeType\": file_data.get(\"mimeType\"),\n",
    "            }\n",
    "            for file_data in json_data.get(\"files\", {}).get(\"main\", []) + json_data.get(\"files\", {}).get(\"additional\", [])\n",
    "        ],\n",
    "        \"contributors\": {\n",
    "            \"curators\": [\n",
    "                {\n",
    "                    \"name\": curator.get(\"name\"),\n",
    "                    \"email\": curator.get(\"email\"),\n",
    "                    \"orcid\": curator.get(\"orcid\")\n",
    "                }\n",
    "                for curator in json_data.get(\"contributors\", {}).get(\"curator\", [])\n",
    "            ],\n",
    "            \"modellers\": [\n",
    "                {\n",
    "                    \"name\": modeller.get(\"name\"),\n",
    "                    \"email\": modeller.get(\"email\"),\n",
    "                    \"orcid\": modeller.get(\"orcid\")\n",
    "                }\n",
    "                for modeller in json_data.get(\"contributors\", {}).get(\"modeller\", [])\n",
    "            ]\n",
    "        },\n",
    "        \"annotations\": [\n",
    "            {\n",
    "                \"qualifier\": annotation.get(\"qualifier\"),\n",
    "                \"accession\": annotation.get(\"accession\"),\n",
    "                \"name\": annotation.get(\"name\"),\n",
    "                \"resource\": annotation.get(\"resource\"),\n",
    "                \"uri\": annotation.get(\"uri\")\n",
    "            }\n",
    "            for annotation in json_data.get(\"modelLevelAnnotations\", [])\n",
    "        ],\n",
    "        \"source\": source\n",
    "    }\n",
    "\n",
    "def process_multiple_json_files(input_folder, output_file, source=None, delete=False):\n",
    "    \"\"\"\n",
    "    Process multiple JSON files, merge metadata, and create separate archives based on format (SBML or SBGN).\n",
    "    \"\"\"\n",
    "    merged_data = {\"SBML\": [], \"SBGN\": []}\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".json\") and filename != os.path.basename(output_file):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                json_data = json.load(file)\n",
    "                metadata = json_metadata_extractor(json_data, source)\n",
    "                format_type = metadata.get(\"format\", \"\")\n",
    "\n",
    "                if source == \"Reactome\":\n",
    "                    if format_type == \"SBML\":\n",
    "                        merged_data[\"SBML\"].append(metadata)\n",
    "                    elif format_type == \"SBGN\":\n",
    "                        merged_data[\"SBGN\"].append(metadata)\n",
    "                else:\n",
    "                    metadata_source = metadata.get(\"source\", \"Unknown\")\n",
    "                    if metadata_source not in merged_data:\n",
    "                        merged_data[metadata_source] = []\n",
    "                    merged_data[metadata_source].append(metadata)\n",
    "\n",
    "    if source == \"Reactome\":\n",
    "        for format_type in [\"SBML\", \"SBGN\"]:\n",
    "            output_subfile = f\"{output_file}_{format_type}.json\"\n",
    "            with open(output_subfile, \"w\") as outfile:\n",
    "                json.dump(merged_data[format_type], outfile, indent=4)\n",
    "            print(f\"{BLUE}File created for {format_type} in {output_subfile}.{RESET}\")\n",
    "    else:\n",
    "        with open(output_file, \"w\") as outfile:\n",
    "            json.dump(merged_data, outfile, indent=4)\n",
    "        print(f\"{BLUE}File created in {output_file}.{RESET}\")\n",
    "\n",
    "\n",
    "    if delete:\n",
    "        for filename in os.listdir(input_folder):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            if filename.endswith(\".json\") and filename != os.path.basename(output_file):\n",
    "                os.remove(file_path)\n",
    "        print(f\"{BLUE}Source files deleted from {input_folder}, except {os.path.basename(output_file)}.{RESET}\")\n",
    "    else:\n",
    "        print(f\"{BLUE}Source files not deleted. Set delete=True to remove them.{RESET}\")\n"
   ],
   "id": "9a68645a2bb19bc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "1) Appears to work properly.\n",
    "2) First nested dictionary key appears to be source (BioModels). Needs to be checked because may be redundant with Source.\n",
    "\"\"\"\n",
    "input_folder = os.path.join(root_path, \"models/BioModels/SBML/\")\n",
    "output_file = os.path.join(root_path, \"models/BioModels/SBML/merged_metadata.json\")\n",
    "custom_source = \"BioModels\"\n",
    "process_multiple_json_files(input_folder, output_file, source=custom_source, delete=True)"
   ],
   "id": "c7f37b6f20a58bcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Enhanced version, works with files repartition BioModels/Reactome and SBML/SBGN :",
   "id": "d49c51990536954d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T20:53:40.828321Z",
     "start_time": "2025-01-26T20:53:40.821844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BLUE = '\\033[94m'\n",
    "RED = '\\033[91m'\n",
    "RESET = '\\033[0m'"
   ],
   "id": "be72dc8e296af199",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T21:01:08.647760Z",
     "start_time": "2025-01-26T21:01:08.575069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def json_metadata_extractor(json_data):\n",
    "    \"\"\"Extract some relevant metadata from a given JSON file.\"\"\"\n",
    "    return {\n",
    "        \"name\": json_data.get(\"name\"),\n",
    "        \"description\": json_data.get(\"description\"),\n",
    "        \"format\": json_data.get(\"format\", {}).get(\"name\"),\n",
    "        \"publication\": {\n",
    "            \"title\": json_data.get(\"publication\", {}).get(\"title\"),\n",
    "            \"journal\": json_data.get(\"publication\", {}).get(\"journal\"),\n",
    "            \"year\": json_data.get(\"publication\", {}).get(\"year\"),\n",
    "            \"authors\": [\n",
    "                {\n",
    "                    \"name\": author.get(\"name\"),\n",
    "                    \"institution\": author.get(\"institution\"),\n",
    "                    \"orcid\": author.get(\"orcid\")\n",
    "                }\n",
    "                for author in json_data.get(\"publication\", {}).get(\"authors\", [])\n",
    "            ],\n",
    "            \"link\": json_data.get(\"publication\", {}).get(\"link\")\n",
    "        },\n",
    "        \"files\": [\n",
    "            {\n",
    "                \"name\": file_data.get(\"name\"),\n",
    "                \"description\": file_data.get(\"description\"),\n",
    "                \"fileSize\": file_data.get(\"fileSize\"),\n",
    "                \"mimeType\": file_data.get(\"mimeType\"),\n",
    "            }\n",
    "            for file_data in json_data.get(\"files\", {}).get(\"main\", []) + json_data.get(\"files\", {}).get(\"additional\", [])\n",
    "        ],\n",
    "        \"contributors\": {\n",
    "            \"curators\": [\n",
    "                {\n",
    "                    \"name\": curator.get(\"name\"),\n",
    "                    \"email\": curator.get(\"email\"),\n",
    "                    \"orcid\": curator.get(\"orcid\")\n",
    "                }\n",
    "                for curator in json_data.get(\"contributors\", {}).get(\"curator\", [])\n",
    "            ],\n",
    "            \"modellers\": [\n",
    "                {\n",
    "                    \"name\": modeller.get(\"name\"),\n",
    "                    \"email\": modeller.get(\"email\"),\n",
    "                    \"orcid\": modeller.get(\"orcid\")\n",
    "                }\n",
    "                for modeller in json_data.get(\"contributors\", {}).get(\"modeller\", [])\n",
    "            ]\n",
    "        },\n",
    "        \"annotations\": [\n",
    "            {\n",
    "                \"qualifier\": annotation.get(\"qualifier\"),\n",
    "                \"accession\": annotation.get(\"accession\"),\n",
    "                \"name\": annotation.get(\"name\"),\n",
    "                \"resource\": annotation.get(\"resource\"),\n",
    "                \"uri\": annotation.get(\"uri\")\n",
    "            }\n",
    "            for annotation in json_data.get(\"modelLevelAnnotations\", [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def process_multiple_json_files(input_folder, delete=False):\n",
    "    \"\"\"Process JSON files and create separate metadata files for models.\"\"\"\n",
    "\n",
    "    metadata_folder = \"../metadata\"\n",
    "    os.makedirs(metadata_folder, exist_ok=True)\n",
    "    models_file = os.path.join(metadata_folder, \"models_metadata.json\")\n",
    "    biomodels_file = os.path.join(metadata_folder, \"metadata_BioModels.json\")\n",
    "    reactome_file = os.path.join(metadata_folder, \"metadata_Reactome.json\")\n",
    "\n",
    "    merged_data = {\"models\": {}}\n",
    "    biomodels_data = {}\n",
    "    reactome_data = {}\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".json\") and not filename.startswith(\".\"):  # Skip hidden files\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                json_data = json.load(file)\n",
    "                metadata = json_metadata_extractor(json_data)\n",
    "\n",
    "                merged_data[\"models\"].append(metadata)\n",
    "\n",
    "                if \"BioModels\" in filename:\n",
    "                    biomodels_data.append(metadata)\n",
    "                elif \"Reactome\" in filename:\n",
    "                    reactome_data.append(metadata)\n",
    "\n",
    "    # merged model\n",
    "    with open(models_file, \"w\") as outfile:\n",
    "        json.dump(merged_data, outfile, indent=4)\n",
    "    print(f\"Created {models_file}\")\n",
    "\n",
    "    # BioModels\n",
    "    with open(biomodels_file, \"w\") as outfile:\n",
    "        json.dump({\"BioModels\": biomodels_data}, outfile, indent=4)\n",
    "    print(f\"Created {biomodels_file}\")\n",
    "\n",
    "    # Reactome\n",
    "    with open(reactome_file, \"w\") as outfile:\n",
    "        json.dump({\"Reactome\": reactome_data}, outfile, indent=4)\n",
    "    print(f\"Created {reactome_file}\")\n",
    "\n",
    "    # Delete source files if True\n",
    "    if delete:\n",
    "        for filename in os.listdir(input_folder):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            if filename.endswith(\".json\") and not filename.startswith(\".\"):\n",
    "                os.remove(file_path)\n",
    "        print(f\"Source files deleted from {input_folder}.\")\n",
    "    else:\n",
    "        print(f\"{BLUE}Source files not deleted. Set delete = True to remove them.{RESET}\")"
   ],
   "id": "509344a5064eb52f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T21:02:05.811985Z",
     "start_time": "2025-01-26T21:02:05.795253Z"
    }
   },
   "cell_type": "code",
   "source": "process_multiple_json_files(\"../metadata/Raw\", delete=False)",
   "id": "986d509740abcc3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ../metadata/models_metadata.json\n",
      "Created ../metadata/metadata_BioModels.json\n",
      "Created ../metadata/metadata_Reactome.json\n",
      "\u001B[94mSource files not deleted. Set delete = True to remove them.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8866bff4d21ff5a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
